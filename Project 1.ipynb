{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "## Quantitative Analysis of New York City Traffic Congestion\n",
    "### How is the pause of issuing FHV licenses improving traffic congestion and earnings in Manhattan Borough\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Start the project by importing library and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import folium\n",
    "import json\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer # used for handling missing data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data\n",
    "from sklearn.model_selection import train_test_split # used for splitting training and testing data\n",
    "from sklearn.preprocessing import StandardScaler # used for feature scaling\n",
    "from folium.plugins import FastMarkerCluster\n",
    "from folium.plugins import HeatMap\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.tile_providers import get_provider, Vendors\n",
    "from bokeh.io import save, reset_output, output_notebook\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Filtered warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Read the dataset and use pickle to save the run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gre_19_07 = pd.read_csv(\"green_tripdata_2019-07.csv\", header=0,low_memory=False,  encoding='latin-1')\n",
    "gre_19_08 = pd.read_csv(\"green_tripdata_2019-08.csv\", header=0,low_memory=False,  encoding='latin-1')\n",
    "yel_19_07 = pd.read_csv(\"yellow_tripdata_2019-07.csv\", header=0,low_memory=False,  encoding='latin-1')\n",
    "yel_19_08 = pd.read_csv(\"yellow_tripdata_2019-08.csv\", header=0,low_memory=False,  encoding='latin-1')\n",
    "\n",
    "gre_18_07 = pd.read_csv(\"green_tripdata_2018-07.csv\", header=0,low_memory=False,  encoding='latin-1')\n",
    "gre_18_08 = pd.read_csv(\"green_tripdata_2018-08.csv\", header=0,low_memory=False,  encoding='latin-1')\n",
    "yel_18_07 = pd.read_csv(\"yellow_tripdata_2019-07.csv\", header=0,low_memory=False,  encoding='latin-1')\n",
    "yel_18_08 = pd.read_csv(\"yellow_tripdata_2019-08.csv\", header=0,low_memory=False,  encoding='latin-1')\n",
    "\n",
    "\n",
    "gre_19_07.to_pickle('green_tripdata_2019_07.pkl')\n",
    "gre_19_08.to_pickle('green_tripdata_2019_08.pkl')\n",
    "yel_19_07.to_pickle('yellow_tripdata_2019_07.pkl')\n",
    "yel_19_08.to_pickle('yellow_tripdata_2019_08.pkl')\n",
    "\n",
    "gre_18_07.to_pickle('green_tripdata_2018_07.pkl')\n",
    "gre_18_08.to_pickle('green_tripdata_2018_08.pkl')\n",
    "yel_18_07.to_pickle('yellow_tripdata_2018_07.pkl')\n",
    "yel_18_08.to_pickle('yellow_tripdata_2018_08.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickle_yel_18_07 = pd.read_pickle('yellow_tripdata_2018_07.pkl')\n",
    "df_pickle_yel_18_08 = pd.read_pickle('yellow_tripdata_2018_08.pkl')\n",
    "df_pickle_yel_19_07 = pd.read_pickle('yellow_tripdata_2019_07.pkl')\n",
    "df_pickle_yel_19_08 = pd.read_pickle('yellow_tripdata_2019_08.pkl')\n",
    "\n",
    "\n",
    "df_pickle_gre_18_07 = pd.read_pickle('green_tripdata_2018_07.pkl')\n",
    "df_pickle_gre_18_08 = pd.read_pickle('green_tripdata_2018_08.pkl')\n",
    "df_pickle_gre_19_07 = pd.read_pickle('green_tripdata_2019_07.pkl')\n",
    "df_pickle_gre_19_08 = pd.read_pickle('green_tripdata_2019_08.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of External datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"central_park_weather.csv\")\n",
    "weather.to_pickle(\"weather.pkl\")\n",
    "df_pickle_weather = pd.read_pickle(\"weather.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The weather and traffic speed data are preprocessed in other notebooks, and loaded here. \n",
    "###### Because the dataset is too big to upload, I use Jupyter notebook to preprocess the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv(\"new_df_weather\") #Preprocess weather dataset.ipynb\n",
    "df_speed = pd.read_csv(\"new_df_traffic\") #Preprocessing of traffic data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### combine the datasets together for visualisation and other analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yel_19 = df_pickle_yel_19_07.append([df_pickle_yel_19_08])\n",
    "df_yel_18 = df_pickle_yel_18_07.append([df_pickle_yel_18_08])\n",
    "\n",
    "df_gre_19 = df_pickle_gre_19_07.append([df_pickle_gre_19_08])\n",
    "df_gre_18 = df_pickle_gre_18_07.append([df_pickle_gre_18_08])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yel = df_yel_18.append([df_yel_19])\n",
    "df_gre = df_gre_18.append([df_gre_19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtered all instances that have 0 passenger count\n",
    "df_yel = df_yel[df_yel[\"passenger_count\"]!=0]\n",
    "df_gre = df_gre[df_gre[\"passenger_count\"]!=0]\n",
    "\n",
    "#Filtered all instances that have 0 trip distance\n",
    "df_yel = df_yel[df_yel[\"trip_distance\"]!=0]\n",
    "df_gre = df_gre[df_gre[\"trip_distance\"]!=0]\n",
    "\n",
    "#Filtered all instances that have payment 1 and 2. \n",
    "#I didn't consider tips as a relevent attribute in my study, so card and cash payments are all good.\n",
    "df_yel = df_yel[(df_yel[\"payment_type\"]<=2.0)]\n",
    "df_gre = df_gre[(df_gre[\"payment_type\"]<=2.0)]\n",
    "\n",
    "#Filtered RateCodeID by only choose the Standard rate.\n",
    "df_yel = df_yel[(df_yel[\"RatecodeID\"]==1.0)]\n",
    "df_gre = df_gre[(df_gre[\"RatecodeID\"]==1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format datetime\n",
    "#repeat the same precedure for green taxi\n",
    "df_yel['tpep_pickup_datetime']=pd.to_datetime(df_yel['tpep_pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_yel['tpep_dropoff_datetime']=pd.to_datetime(df_yel['tpep_dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_gre['lpep_pickup_datetime']=pd.to_datetime(df_gre['lpep_pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_gre['lpep_dropoff_datetime']=pd.to_datetime(df_gre['lpep_dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "#Splitting timestamp column into separate date and time columns\n",
    "df_yel['Dates_pickup'] = pd.to_datetime(df_yel['tpep_pickup_datetime']).dt.date\n",
    "df_yel['Time_pickup'] = pd.to_datetime(df_yel['tpep_pickup_datetime']).dt.time\n",
    "\n",
    "df_yel['Dates_dropoff'] = pd.to_datetime(df_yel['tpep_dropoff_datetime']).dt.date\n",
    "df_yel['Time_dropoff'] = pd.to_datetime(df_yel['tpep_dropoff_datetime']).dt.time\n",
    "\n",
    "#Splitting timestamp column into separate date and time columns\n",
    "df_gre['Dates_pickup'] = pd.to_datetime(df_gre['lpep_pickup_datetime']).dt.date\n",
    "df_gre['Time_pickup'] = pd.to_datetime(df_gre['lpep_pickup_datetime']).dt.time\n",
    "\n",
    "df_gre['Dates_dropoff'] = pd.to_datetime(df_gre['lpep_dropoff_datetime']).dt.date\n",
    "df_gre['Time_dropoff'] = pd.to_datetime(df_gre['lpep_dropoff_datetime']).dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                        float64\n",
       "lpep_pickup_datetime     datetime64[ns]\n",
       "lpep_dropoff_datetime    datetime64[ns]\n",
       "store_and_fwd_flag               object\n",
       "RatecodeID                      float64\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "ehail_fee                       float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "payment_type                    float64\n",
       "trip_type                       float64\n",
       "congestion_surcharge            float64\n",
       "Dates_pickup                     object\n",
       "Time_pickup                      object\n",
       "Dates_dropoff                    object\n",
       "Time_dropoff                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gre.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                        float64\n",
       "tpep_pickup_datetime     datetime64[ns]\n",
       "tpep_dropoff_datetime    datetime64[ns]\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "RatecodeID                      float64\n",
       "store_and_fwd_flag               object\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "payment_type                    float64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "congestion_surcharge            float64\n",
       "Dates_pickup                     object\n",
       "Time_pickup                      object\n",
       "Dates_dropoff                    object\n",
       "Time_dropoff                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yel.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>...</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Dates_pickup</th>\n",
       "      <th>Time_pickup</th>\n",
       "      <th>Dates_dropoff</th>\n",
       "      <th>Time_dropoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-07-01 00:46:04</td>\n",
       "      <td>2019-07-01 01:05:46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:46:04</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>01:05:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-07-01 00:28:09</td>\n",
       "      <td>2019-07-01 00:51:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:28:09</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-07-01 00:57:07</td>\n",
       "      <td>2019-07-01 01:11:41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>246</td>\n",
       "      <td>141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:57:07</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>01:11:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-07-01 00:06:16</td>\n",
       "      <td>2019-07-01 00:33:14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:06:16</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:33:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-07-01 00:37:19</td>\n",
       "      <td>2019-07-01 00:52:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:37:19</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:52:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "1       2.0  2019-07-01 00:46:04   2019-07-01 01:05:46              1.0   \n",
       "6       1.0  2019-07-01 00:28:09   2019-07-01 00:51:00              1.0   \n",
       "7       1.0  2019-07-01 00:57:07   2019-07-01 01:11:41              1.0   \n",
       "8       4.0  2019-07-01 00:06:16   2019-07-01 00:33:14              1.0   \n",
       "9       4.0  2019-07-01 00:37:19   2019-07-01 00:52:30              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "1           4.16         1.0                  N           234            25   \n",
       "6           2.40         1.0                  N           142            68   \n",
       "7           3.00         1.0                  N           246           141   \n",
       "8           7.89         1.0                  N            50            80   \n",
       "9           4.09         1.0                  N            80            97   \n",
       "\n",
       "   payment_type  ...  mta_tax  tip_amount  tolls_amount  \\\n",
       "1           2.0  ...      0.5        0.00           0.0   \n",
       "6           1.0  ...      0.5        3.35           0.0   \n",
       "7           2.0  ...      0.5        0.00           0.0   \n",
       "8           1.0  ...      0.5        5.96           0.0   \n",
       "9           2.0  ...      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Dates_pickup  \\\n",
       "1                    0.3         20.30                   2.5    2019-07-01   \n",
       "6                    0.3         20.15                   2.5    2019-07-01   \n",
       "7                    0.3         16.30                   2.5    2019-07-01   \n",
       "8                    0.3         35.76                   2.5    2019-07-01   \n",
       "9                    0.3         16.30                   0.0    2019-07-01   \n",
       "\n",
       "   Time_pickup Dates_dropoff Time_dropoff  \n",
       "1     00:46:04    2019-07-01     01:05:46  \n",
       "6     00:28:09    2019-07-01     00:51:00  \n",
       "7     00:57:07    2019-07-01     01:11:41  \n",
       "8     00:06:16    2019-07-01     00:33:14  \n",
       "9     00:37:19    2019-07-01     00:52:30  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yel.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Dates_pickup</th>\n",
       "      <th>Time_pickup</th>\n",
       "      <th>Dates_dropoff</th>\n",
       "      <th>Time_dropoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-07-01 00:41:27</td>\n",
       "      <td>2018-07-01 01:06:15</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.37</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>28.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>00:41:27</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>01:06:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-07-01 00:43:30</td>\n",
       "      <td>2018-07-01 00:59:51</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>00:43:30</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>00:59:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-07-01 01:00:40</td>\n",
       "      <td>2018-07-01 01:13:36</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>01:00:40</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>01:13:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-07-01 00:23:43</td>\n",
       "      <td>2018-07-01 00:32:49</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>223</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>00:23:43</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>00:32:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-07-01 00:20:41</td>\n",
       "      <td>2018-07-01 00:24:05</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>00:20:41</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>00:24:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0       2.0  2018-07-01 00:41:27   2018-07-01 01:06:15                  N   \n",
       "1       1.0  2018-07-01 00:43:30   2018-07-01 00:59:51                  N   \n",
       "2       2.0  2018-07-01 01:00:40   2018-07-01 01:13:36                  N   \n",
       "3       1.0  2018-07-01 00:23:43   2018-07-01 00:32:49                  N   \n",
       "4       2.0  2018-07-01 00:20:41   2018-07-01 00:24:05                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0            33            50              5.0           6.37   \n",
       "1         1.0            25           224              1.0           5.30   \n",
       "2         1.0            65           225              1.0           2.98   \n",
       "3         1.0             7           223              1.0           1.40   \n",
       "4         1.0            33            25              2.0           1.03   \n",
       "\n",
       "   fare_amount  ...  ehail_fee  improvement_surcharge  total_amount  \\\n",
       "0         22.5  ...        NaN                    0.3         28.56   \n",
       "1         18.0  ...        NaN                    0.3         22.56   \n",
       "2         12.0  ...        NaN                    0.3         13.30   \n",
       "3          8.0  ...        NaN                    0.3          9.30   \n",
       "4          5.0  ...        NaN                    0.3          8.19   \n",
       "\n",
       "   payment_type  trip_type  congestion_surcharge  Dates_pickup  Time_pickup  \\\n",
       "0           1.0        1.0                   NaN    2018-07-01     00:41:27   \n",
       "1           1.0        1.0                   NaN    2018-07-01     00:43:30   \n",
       "2           2.0        1.0                   NaN    2018-07-01     01:00:40   \n",
       "3           2.0        1.0                   NaN    2018-07-01     00:23:43   \n",
       "4           1.0        1.0                   NaN    2018-07-01     00:20:41   \n",
       "\n",
       "   Dates_dropoff  Time_dropoff  \n",
       "0     2018-07-01      01:06:15  \n",
       "1     2018-07-01      00:59:51  \n",
       "2     2018-07-01      01:13:36  \n",
       "3     2018-07-01      00:32:49  \n",
       "4     2018-07-01      00:24:05  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gre.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtered any instances that have the same pickup and dropoff time\n",
    "df_yel = df_yel[df_yel[\"tpep_pickup_datetime\"]!=df_yel[\"tpep_dropoff_datetime\"]]\n",
    "df_gre = df_gre[df_gre[\"lpep_pickup_datetime\"]!=df_gre[\"lpep_dropoff_datetime\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill all NaN value with 0\n",
    "df_yel = df_yel.fillna(0)\n",
    "df_gre = df_gre.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only wanted study attributes\n",
    "df_yel = df_yel[[\"PULocationID\", \"DOLocationID\", \"passenger_count\", \"trip_distance\", \"fare_amount\", \"extra\",\n",
    "                 \"mta_tax\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"payment_type\",\n",
    "                 \"congestion_surcharge\", \"Dates_pickup\", \"Time_pickup\", \"Dates_dropoff\", \"Time_dropoff\"\n",
    "                ]]\n",
    "\n",
    "df_gre = df_gre[[\"PULocationID\", \"DOLocationID\", \"passenger_count\", \"trip_distance\", \"fare_amount\", \"extra\",\n",
    "                 \"mta_tax\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"payment_type\",\n",
    "                \"trip_type\", \"congestion_surcharge\", \"Dates_pickup\", \"Time_pickup\", \"Dates_dropoff\", \"Time_dropoff\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Geospatial Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE = get_provider(\"STAMEN_TERRAIN_RETINA\")\n",
    "\n",
    "reset_output()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf stands for shape file\n",
    "sf = gpd.read_file(\"MAST30034_Python/data/taxi_zones/taxi_zones.shp\")\n",
    "zone = pd.read_csv(\"taxi+_zone_lookup.csv\")\n",
    "\n",
    "# Convert the geometry shape to to latitude and longitude\n",
    "# Please attribute this if you are using it\n",
    "sf['geometry'] = sf['geometry'].to_crs(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a `gdf` with our current dataframe and shapefile data.\n",
    "\n",
    "From `df`, we join using `PULocationID` to match from `sf`'s `LocationID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_Man = sf[sf[\"borough\"] == \"Manhattan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LocationID_Man = sf_Man[\"LocationID\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_yel = gpd.GeoDataFrame(pd.merge(df_yel, sf, left_on='PULocationID', right_on='LocationID')).drop('PULocationID',axis=1)\n",
    "gdf_gre = gpd.GeoDataFrame(pd.merge(df_gre, sf, left_on='PULocationID', right_on='LocationID')).drop('PULocationID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoJSON_yel = gdf_yel[['LocationID','geometry']].drop_duplicates('LocationID').to_json()\n",
    "geoJSON_gre = gdf_gre[['LocationID','geometry']].drop_duplicates('LocationID').to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_yel = folium.Map(location=[40.66, -73.94], tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "\n",
    "# refer to the folium documentations on how to plot aggregated data.\n",
    "m_yel.add_child(folium.Choropleth(\n",
    "    geo_data=geoJSON_yel,\n",
    "    name='choropleth',\n",
    "))\n",
    "\n",
    "m_yel.save('MAST30034_Python/plots/foliumChoroplethMap_yel.html')\n",
    "m_yel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_gre = folium.Map(location=[40.66, -73.94], tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "\n",
    "# refer to the folium documentations on how to plot aggregated data.\n",
    "m_gre.add_child(folium.Choropleth(\n",
    "    geo_data=geoJSON_gre,\n",
    "    name='choropleth',\n",
    "))\n",
    "\n",
    "m_gre.save('MAST30034_Python/plots/foliumChoroplethMap_gre.html')\n",
    "m_gre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_trip_distance = folium.Map(location=[40.66, -73.94], tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "\n",
    "# refer to the folium documentations on more information on how to plot aggregated data.\n",
    "folium.Choropleth(\n",
    "    geo_data=geoJSON_yel, # geoJSON \n",
    "    name='choropleth', # name of plot\n",
    "    data=gdf_yel, # data source\n",
    "    columns=['LocationID','fare_amount'], # the columns required\n",
    "    key_on='properties.LocationID', # this is from the geoJSON's properties\n",
    "    fill_color='OrRd', # color scheme\n",
    "    fill_opacity=0.9,\n",
    "    line_opacity=0.5,\n",
    "    legend_name='Trips' # legend title\n",
    ").add_to(m_trip_distance)\n",
    "\n",
    "m_trip_distance.save('MAST30034_Python/plots/foliumChoroplethMapTrips_yel.html')\n",
    "m_trip_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I want the location only in Manhattan\n",
    "df_yel = df_yel[df_yel[\"PULocationID\"].isin(LocationID_Man) & df_yel[\"DOLocationID\"].isin(LocationID_Man)]\n",
    "df_gre = df_gre[df_gre[\"PULocationID\"].isin(LocationID_Man) & df_gre[\"DOLocationID\"].isin(LocationID_Man)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_yel = gpd.GeoDataFrame(pd.merge(df_yel, sf, left_on='PULocationID', right_on='LocationID')).drop('PULocationID',axis=1)\n",
    "gdf_gre = gpd.GeoDataFrame(pd.merge(df_gre, sf, left_on='PULocationID', right_on='LocationID')).drop('PULocationID',axis=1)\n",
    "geoJSON_yel = gdf_yel[['LocationID','geometry']].drop_duplicates('LocationID').to_json()\n",
    "geoJSON_gre = gdf_gre[['LocationID','geometry']].drop_duplicates('LocationID').to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_trip_distance = folium.Map(location=[40.66, -73.94], tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "\n",
    "# refer to the folium documentations on more information on how to plot aggregated data.\n",
    "folium.Choropleth(\n",
    "    geo_data=geoJSON_yel, # geoJSON \n",
    "    name='choropleth', # name of plot\n",
    "    data=gdf_yel, # data source\n",
    "    columns=['LocationID','fare_amount'], # the columns required\n",
    "    key_on='properties.LocationID', # this is from the geoJSON's properties\n",
    "    fill_color='OrRd', # color scheme\n",
    "    fill_opacity=0.9,\n",
    "    line_opacity=0.5,\n",
    "    legend_name='Trips' # legend title\n",
    ").add_to(m_trip_distance)\n",
    "\n",
    "m_trip_distance.save('MAST30034_Python/plots/foliumChoroplethMapTrips_yel_Man.html')\n",
    "m_trip_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_trip_distance = folium.Map(location=[40.66, -73.94], tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "\n",
    "# refer to the folium documentations on more information on how to plot aggregated data.\n",
    "folium.Choropleth(\n",
    "    geo_data=geoJSON_gre, # geoJSON \n",
    "    name='choropleth', # name of plot\n",
    "    data=gdf_gre, # data source\n",
    "    columns=['LocationID','fare_amount'], # the columns required\n",
    "    key_on='properties.LocationID', # this is from the geoJSON's properties\n",
    "    fill_color='OrRd', # color scheme\n",
    "    fill_opacity=0.9,\n",
    "    line_opacity=0.5,\n",
    "    legend_name='Trips' # legend title\n",
    ").add_to(m_trip_distance)\n",
    "\n",
    "m_trip_distance.save('MAST30034_Python/plots/foliumChoroplethMapTrips_gre_Man.html')\n",
    "m_trip_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by the dataset by dates\n",
    "new_df_yel = df_yel.groupby([df_yel['Dates_pickup']])[\"passenger_count\", \"trip_distance\", \"fare_amount\", \n",
    "                                                      \"extra\",\"mta_tax\", \"tolls_amount\", \"improvement_surcharge\", \n",
    "                                                      \"total_amount\", \"congestion_surcharge\"].mean()\n",
    "new_df_gre = df_gre.groupby([df_gre['Dates_pickup']])[\"passenger_count\", \"trip_distance\", \"fare_amount\", \n",
    "                                                      \"extra\",\"mta_tax\", \"tolls_amount\", \"improvement_surcharge\", \n",
    "                                                      \"total_amount\", \"congestion_surcharge\"].mean()\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = df_weather[\"\"]\n",
    "\n",
    "\n",
    "df_yel_all = new_df_yel\n",
    "df_weather\n",
    "df_speed\n",
    "columns = ['Score E','Score F']\n",
    "\n",
    "df_add = pd.DataFrame(data=data,columns=columns)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df = pd.concat([df,df_add], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
